{
  "hash": "9e963ec7668d215f082ba3ff02591b17",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Topic Modeling\"\n---\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(topicmodels)\nlibrary(tidyverse)\nlibrary(tidygraph)\nlibrary(ggraph)\nlibrary(arrow)\nlibrary(tidytext)\n```\n:::\n\n\n\n## Overview\n\nTopic modeling is usefully for categorize long text into themes without reading\nfull text. \n\n### Load Data\n\n\n::: {.cell}\n\n```{.r .cell-code  code-summary=\"set up and load data\"}\ngtr_desc = read_parquet(\"data/gtr.parquet\") |> \n  select(id, abstractText)\ngtr_meta = read_csv(\"data/projectsearch-1709481069771.csv\") |> \n  mutate(across(ends_with(\"Date\"), ~as.Date(.x,\"%d/%m/%Y\"))) |> \n  rename(id=ProjectId)\nPARTIAL_PTTN='(/[1-9])$'\n\n## waggle some columns for analytics\ngtr_pj = gtr_meta |>\n  mutate(\n    is_partial = str_detect(ProjectReference, PARTIAL_PTTN),\n    project_ref = str_replace(ProjectReference,PARTIAL_PTTN,\"\"),\n    part = str_extract(ProjectReference, PARTIAL_PTTN) |> \n      str_extract(\"\\\\d+\") |> \n      as.numeric() |> \n      coalesce(0)\n  ) |> \n  # filter(is_partial) |> \n  group_by(project_ref) |>\n  mutate(occurance = n()) |> \n  ungroup() |> \n  dplyr::relocate(ProjectReference, FundingOrgName, LeadROName, id, \n           is_partial,project_ref,part,occurance)\n\n## early stop if this is no longer true\nstopifnot(\n  \"Project Reference is NOT Unique!\"=length(unique(gtr_pj$ProjectReference)) == nrow(gtr_pj),\n  \"Project Refrence contain NA!\"=!any(is.na(gtr_pj$ProjectReference))\n)\n\n## find out about \nunique_prj = gtr_pj |>\n  relocate(ProjectReference, project_ref, id) |> \n  group_by(project_ref) |> \n  mutate(rn=row_number()) |> \n  filter(rn==1) |> \n  select(-rn) |> \n  ungroup()\n\n## find out with text other than continuous project are repeated\nrepeated_text = gtr_desc |> \n  group_by(abstractText) |> \n  mutate(n=n()) |> \n  filter(n!=1) |>\n  arrange(abstractText)\n\n## Take the repeated test one out for now.\nanalysis_prj = unique_prj |> \n  anti_join(repeated_text, by=\"id\") |> \n  mutate(year = lubridate::year(StartDate)) |>\n  inner_join(gtr_desc, by=\"id\")\n```\n:::\n\n\n### Review Abstract Word Count of Abstract\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\"}\nanalysis_prj |> \n  count(ProjectCategory,sort=T)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 28 × 2\n   ProjectCategory                        n\n   <chr>                              <int>\n 1 Studentship                         1338\n 2 Research Grant                      1277\n 3 Collaborative R&D                    402\n 4 Feasibility Studies                  202\n 5 Fellowship                           192\n 6 Knowledge Transfer Partnership       132\n 7 EU-Funded                             77\n 8 Small Business Research Initiative    65\n 9 Study                                 54\n10 Training Grant                        49\n# ℹ 18 more rows\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n## word count histogram\nabstract_words = analysis_prj |> \n  unnest_tokens(word,abstractText) |> \n  anti_join(stop_words)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nJoining with `by = join_by(word)`\n```\n\n\n:::\n\n```{.r .cell-code}\nabstract_words |> \n  count(id,ProjectCategory) |> \n  ggplot() +\n  geom_histogram( fill=\"midnightblue\",aes(x=n) ) +\n  theme_minimal() +\n  ggtitle(\"Abstract Length\") +\n  facet_wrap(~ ProjectCategory)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](05_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\nResearch Grant and Studentship have \"rich\" abstract we can extract on. You probably what to filter down to Research Grant before modeling\n\n## Topic Model\n\n### Topic Modeling using LDA\n\nKey matrix from topic models are:\n\n- Gemma: is proportion of topics for each document\n- Beta: is weight of words for each topic.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\" code-summary=\"code for creating topic modelings\"}\nabstract_word_count = abstract_words |> \n  count(word,id,sort=T)\n\n## this is very expensive process so cached this result for saving rendering time\nif(interactive()) {\n  gtr_dtm = abstract_word_count |> \n    cast_dtm(id,word,n)\n  topics = gtr_dtm |> topicmodels::LDA(k=10)\n  saveRDS(topics, \"cache/05-topics.rds\")\n} else {\n  topics=readRDS(\"cache/05-topics.rds\")\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\" code-summary=\"code for creating topic modelings\"}\ntopics |> \n  tidy(\"beta\") |> \n  group_by(topic) |> \n  slice_max(beta,n=15) |> \n  ggplot(aes(y=reorder_within(term, beta,topic),x= beta )) +\n  geom_col() + \n  scale_y_reordered() +\n  facet_wrap(~ topic,scales=\"free_y\") +\n  theme_minimal() +\n  xlab(\"beta (higher indicate more relevant to topic)\") +\n  ylab(\"term\") +\n  ggtitle(\"LDA model output result (beta)\")\n```\n\n::: {.cell-output-display}\n![](05_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\nThis is a typical graph used to visualize LDA output. `beta` indicate importance of words to extracted topic.\n\nHowever, it is still not easy to tell what these topic actually are. \nTo explore topic, \n`n-gram` to link most frequently linked words, which will give us a picture of how \"these key words\" links together.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\"}\n## examples of top 10 topics.\ntop10_gamma = topics |> \n  tidy(\"gamma\") |> \n  group_by(topic) |> \n  slice_max(gamma) |> \n  rename(id=document)\ntop10_gamma |> left_join(gtr_desc,by=\"id\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 10 × 4\n# Groups:   topic [10]\n   id                                   topic gamma abstractText                \n   <chr>                                <int> <dbl> <chr>                       \n 1 7E7A8295-0B52-46C2-A6C8-1956056FE209     1 0.999 \"In partnership with the As…\n 2 4397428D-FBA6-478D-A52B-1C0232F7D4A4     2 0.999 \"The context of the researc…\n 3 A64CF8F6-E8F1-4A67-ACD8-F00A17D55833     3 0.999 \"Hair follicle development …\n 4 E273B321-E931-44F2-9FCC-54A55B2EE320     4 0.999 \"On June 19th, 2017, the Ne…\n 5 BDA3F2AA-0614-4ECE-9766-96C712CC7544     5 0.999 \"Invasive non-native specie…\n 6 7A9FCA6C-194C-4207-9A46-C77BB5FD6D4C     6 0.999 \"This fellowship analyses B…\n 7 1EFB61B0-740C-4754-8E4E-E0AF963D3D20     7 0.999 \"One of the great challenge…\n 8 7E5F0B59-A654-4151-9E82-5A49B0358751     8 0.999 \"In the Calvin-Benson cycle…\n 9 BF012599-0BBD-4702-89F7-5E214599310D     9 0.999 \"Magnetic data storage syst…\n10 931199B4-F6B9-4003-9874-446650A83F4A    10 0.999 \"With Covid-19 causing sign…\n```\n\n\n:::\n:::\n\n\n### Topic against Project Category\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## gamma score over the years\n## top gamma's n-gram\ntopic_binded = topics |> \n  tidy(\"gamma\") |> \n  filter(gamma > 0.8) |> # 0.8 is a number we can be sure there is only one topic\n                         # for one document\n  rename(id=document) |> \n  left_join(analysis_prj, \"id\")\n\ntopic_binded |>\n  select(topic, ProjectCategory) |>\n  mutate(topic_chr=fct_inorder(as.character(topic)) ) |> \n  complete(topic_chr,ProjectCategory) |> \n  ggplot() + \n  geom_bin2d(aes(x=topic_chr, y = ProjectCategory)) +\n  theme_minimal() +\n  scale_fill_viridis_c(option = \"F\",trans=\"sqrt\") +\n  ggtitle(\"Topic Against Porject Category\") +\n  coord_equal()\n```\n\n::: {.cell-output-display}\n![](05_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"useful function create specific plot\"}\n## For compute bigram ---------------------------------------------\n#' Calculate bigram given document and field\n#' @param doc_df document number\n#' @param field column of text field\n#' @param doc_id id indicating text comes from in fact\ncompute_bi_gram = function(doc_df,field) {\n  .gvars = group_vars(doc_df)\n  if(length(.gvars)==0) {\n    Gvars=quo(NULL)\n  } else {\n    Gvars=quo({any_of(.gvars)})\n  }\n  doc_df |> \n    # select({{field}},!!Gvars ) |> \n    unnest_tokens(pharse,{{field}},'ngrams',n=2) |> \n    separate(pharse, into=c(\"word1\",\"word2\"),sep=\" \") |> \n    ## clear up stopwords\n    anti_join(stop_words, c(\"word1\"=\"word\")) |> \n    anti_join(stop_words, c(\"word2\"=\"word\")) |> \n    filter(!is.na(word1) & !is.na(word2))\n}\n#' customer counting function that also\ncount_bi_gram = function(bi_gram,...) {\n  bi_gram |> \n    group_by(word1,word2, .add=T) |> \n    group_by(..., .add=T) |> \n    summarise(n=n(),.groups=\"drop\") |> \n    arrange(desc(n))\n}\n## plot functions --------------------------------\nplot_beta=function(lda_model,ki,max_n=15) {\n  lda_model |> \n    tidy(\"beta\") |> \n    filter(topic == ki) |> \n    group_by(topic) |> \n    slice_max(beta,n=max_n) |> \n    ggplot(aes(y=reorder_within(term, beta,topic),x= beta )) +\n    geom_col(fill=\"royalblue3\") + \n    scale_y_reordered() +\n    theme_minimal()\n}\nplot_word_graph=function(bi_gram_tokens,\n                         ki,\n                         top_n=15,\n                         model=NULL,\n                         color= \"cyan4\"\n                         ) {\n  if(!is.null(model)) {\n    beta=tidy(model,\"beta\") |> \n      filter(topic == ki)\n    .add_beta = function(x) {\n      activate(x,nodes) |> \n        left_join(beta, by=c(\"name\"=\"term\"))\n    }\n    .add_node_marker = function() {\n      geom_node_point(aes(size=beta))\n    }\n  } else {\n    .add_beta = \\(x) x\n    .add_node_marker = \\() geom_node_point(size=5)\n  }\n  typical_graph=bi_gram_tokens |> \n    count_bi_gram(topic) |> \n    relocate(word1,word2) |> \n    as_tbl_graph()\n  ## filter bi-gram graph and plot\n  g = typical_graph |> \n    .add_beta() |> \n    activate(edges) |>\n    filter(topic == ki) |> \n    arrange(desc(n)) |> \n    filter(row_number() <= top_n) |> \n    activate(nodes) |> \n    filter(!node_is_isolated())\n  ## plot one single graph\n  g |> \n    ggraph('kk') +\n    geom_edge_link(aes(width=n, alpha=n),color= color) +\n    geom_node_text(aes(label=name),repel = T) +\n    .add_node_marker() +\n    theme_void() +\n    ggtitle(paste(\"topic\",ki))\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"pre compute expensive data\"}\n## data ----------------------\n## bind topic result \ntopic_binded=topics |> \n  tidy(\"gamma\") |> \n  filter(gamma > 0.8) |> # 0.8 is a number we can be sure there is only one topic\n                         # for one document\n  rename(id=document) |> \n  left_join(analysis_prj, \"id\")\n\ntypical_docs = topic_binded |> \n  group_by(topic) |> \n  slice_max(gamma,n=1) |> \n  select(topic,abstractText)\n\n## compute a graphic exploration\n## combine to bi-gram this is usually the expensive one\nbi_gram_tok = topic_binded |>\n  compute_bi_gram(abstractText)\n## graph -----------------------\nplot_topics = function(model,reps_tk,reps_docs,topic_ki,color= \"cyan4\") {\n  ## topic graph\n  g1 = reps_tk |>\n    plot_word_graph(topic_ki,top_n = 20,model=model,color=color) +\n    ggtitle(paste0(\"Topic\", topic_ki,\"\"))\n  \n  ## beta plot\n  g2 = model |> \n    plot_beta(topic_ki,max_n = 20) +\n    ggtitle(\"Beta, words most represent topics\")\n  \n  ## add example texts\n  foot_notes = reps_docs |> \n    filter(topic == topic_ki) |> \n    pull(abstractText) |> \n    stringr::str_wrap(160) |> \n    stringr::str_trunc(500)\n  g3 = ggplot() + theme_void() + geom_text(aes(x=0,y=0,label = foot_notes)) +\n    ggtitle(\"Example\")\n  ggpubr::ggarrange(g1,g2) |> \n    ggpubr::ggarrange(g3,nrow=2, heights=c(8,5))\n}\n```\n:::\n\n\nThe topic modeling are in fact picking up different types of topics. Particularly \"*Studentship*\" is extracted as *topic 2*, \"*Collaborative R & D*\" is almost exclusively extracted as *topic 10*.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nG=map(c(2,10),~plot_topics(model=topics,\n                        reps_tk=bi_gram_tok, \n                        reps_docs=typical_docs,\n                        topic_ki=.x))\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: The `trans` argument of `continuous_scale()` is deprecated as of ggplot2 3.5.0.\nℹ Please use the `transform` argument instead.\n```\n\n\n:::\n\n```{.r .cell-code}\nggpubr::ggarrange(plotlist=G,nrow=2)\n```\n\n::: {.cell-output-display}\n![](05_files/figure-html/unnamed-chunk-11-1.png){width=1440}\n:::\n:::\n\n\n*Topic 3* seems to be describe about \"machine learning\". One of the hot words. It makes no surprise that some how related to *student ship*.\n\n*topic 8*, *topic 9* both are very scientific. As we can see the description are very sentific and specific to particular field.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nG=map(c(8,9),~plot_topics(model=topics,\n                        reps_tk=bi_gram_tok, \n                        reps_docs=typical_docs,\n                        topic_ki=.x))\nggpubr::ggarrange(plotlist=G,nrow=2)\n```\n\n::: {.cell-output-display}\n![](05_files/figure-html/unnamed-chunk-12-1.png){width=1440}\n:::\n:::\n\n\n*topic 8* probably sounds like biology. *topic 9* sounds like material science.\n\nIt also interesting to see that although term \"*artificial intelligence*\" is frequently linked together, the \"beta\" score is actually low.\n\n### Topic Against Institution\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntopics |> \n  tidy(\"gamma\") |> \n  filter(gamma > 0.75) |> \n  left_join(gtr_desc,c(\"document\"=\"id\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1,762 × 4\n   document                             topic gamma abstractText                \n   <chr>                                <int> <dbl> <chr>                       \n 1 D3519C9D-7595-4C4E-983B-8B1B392C7257     1 0.981 \"PROJECT APPROACH\\nThe C-ST…\n 2 8FD8E9CE-3E40-4FF5-8C5B-F70059C8204B     1 0.801 \"We remember many events fr…\n 3 2DF9A824-3A1B-4660-A686-7084E793B434     1 0.915 \"Digital games have extraor…\n 4 A399E04D-43CF-44D4-A124-31C33772D5C8     1 0.927 \"The project provides a pla…\n 5 B01F4112-691B-4D55-96E5-6FE1A82AFFE2     1 0.913 \"The digital games industry…\n 6 31AD9973-70D5-4514-B07B-1BC2D8FBDFB3     1 0.868 \"This research will explore…\n 7 7E7A8295-0B52-46C2-A6C8-1956056FE209     1 0.999 \"In partnership with the As…\n 8 08CA7336-763E-4976-8849-FA89EA858B44     1 0.943 \"Up to 4% of people who are…\n 9 29CB95C0-B9E4-4918-A58D-5BC8B7D85E4D     1 0.893 \"Around 6,200 per year are …\n10 0FE2D3FE-0C65-42C6-BBBE-2249D2C1AEFD     1 0.888 \"Contemporary art instituti…\n# ℹ 1,752 more rows\n```\n\n\n:::\n:::\n\n\n### Focus on Research Grant\n\nThe histogram shows us that *research grant* is the biggest chunk. So let's apply \"research grant\" by itself to see if there anything interesting.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## filter to research project only\nres_prj = analysis_prj |> \n  filter(ProjectCategory==\"Research Grant\")\n\n## research document term matrix\nres_dtm = res_prj |> \n  select(id,abstractText) |> \n  unnest_tokens(word,abstractText) |> \n  anti_join(stop_words) |> \n  count(id,word,sort=T) |> \n  cast_dtm(id,word,n)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nJoining with `by = join_by(word)`\n```\n\n\n:::\n\n```{.r .cell-code}\n## research lda models \nif(interactive() ) {\n  res_lda = res_dtm |> topicmodels::LDA(k=10)\n  saveRDS(res_lda,\"cache/05-res_lda.rds\")\n} else {\n  res_lda=readRDS(\"cache/05-res_lda.rds\")\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code  code-summary=\"lda output for research fund abstract text only\"}\nres_reps = res_lda |> \n  tidy(\"gamma\") |> \n  filter(gamma > 0.75) |> # 0.75 is a number we can be sure there is only one topic\n                         # for one document\n  rename(id=document) |> \n  left_join(analysis_prj, \"id\")\n\n## compute three data sets\nres_betas = res_lda |> tidy(\"beta\")\nres_bi_gram = res_reps |> \n  compute_bi_gram(abstractText)\nres_reps_top = res_reps |> \n  group_by(topic) |> \n  slice_max(gamma,n=1)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n## a simple test of co-herence\nres_reps |> \n  group_by(topic) |> \n  slice_max(gamma,n=1) |> \n  select(topic,LeadROName,Department,Title)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 11 × 4\n# Groups:   topic [10]\n   topic LeadROName                        Department                      Title\n   <int> <chr>                             <chr>                           <chr>\n 1     1 University of the West of England Faculty of Business and Law     Deco…\n 2     1 Coventry University               Ctr for Business in Society     Deco…\n 3     2 University of Southampton         Human Development and Health    Feta…\n 4     3 Loughborough University           Loughborough University in Lon… MIMI…\n 5     4 University of Strathclyde         Inst of Pharmacy and Biomedica… Made…\n 6     5 Oxford Brookes University         Faculty of Health and Life Sci… 21EN…\n 7     6 University of Cambridge           Haematology                     Impr…\n 8     7 University of Cambridge           Computer Science and Technology A Un…\n 9     8 University of York                Computer Science                The …\n10     9 University of Edinburgh           Sch of Engineering              Cent…\n11    10 University of Exeter              Physics                         A Pl…\n```\n\n\n:::\n:::\n\n\nJust by looking at department of research topic, it seems that some of the topic perhaps not as coherent as we hopped. It is possible that we need less topic than 10 perhaps.\n\nLets do another sample:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nres_reps |> \n  group_by(topic) |> \n  slice_sample(n=1) |> \n  select(topic,LeadROName,Department,Title)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 10 × 4\n# Groups:   topic [10]\n   topic LeadROName                        Department                      Title\n   <int> <chr>                             <chr>                           <chr>\n 1     1 University of Surrey              Computing Science               Mode…\n 2     2 Cardiff University                School of Physics and Astronomy Rapi…\n 3     3 University of Southampton         Sch of Chemistry                Arti…\n 4     4 King's College London             Informatics                     PLEA…\n 5     5 University of Bristol             Earth Sciences                  Real…\n 6     6 Royal Veterinary College          Comparative Biomedical Science… Unra…\n 7     7 Edinburgh Napier University       School of Computing             Natu…\n 8     8 University of the West of England Faculty of Environment and Tec… Publ…\n 9     9 University of Liverpool           Engineering (Level 1)           EPSR…\n10    10 University of Cambridge           Physics                         Quan…\n```\n\n\n:::\n:::\n\n\nSo actually this maybe doing alright. Lets analysis department fields.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nres_reps |> \n  select(topic,LeadROName,Department,Title,id) |> \n  unnest_tokens(word,Department) |> \n  anti_join(stop_words,\"word\") |> \n  # filter(!word %in% c(\"sch\",\"school\",'science')) |> \n  count(id,word,topic,sort=T) |> \n  bind_tf_idf(word,id,n) |>\n  group_by(topic) |> \n  slice_max(tf_idf,n=10) |> \n  ggplot(aes(x = tf_idf, y = reorder_within(word, tf_idf, topic) )) + \n  geom_col(fill=\"black\") +\n  scale_y_reordered() +\n  facet_wrap(~ topic,scale=\"free_y\") +\n  theme_minimal() +\n  ggtitle(\"Topic Versus Research Insititution Deparatment\")\n```\n\n::: {.cell-output-display}\n![](05_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n:::\n\n\nSo 5 and 6 could be similar, 3 and 4 could stand one topic. But we cannot be too sure yet. So\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"show\"}\n## this process also merge similarish topics\ntopic_guess = c(\n  \"AI & Public Wellfare\",\n  \"Health & Medical\",\n  \"Computer & Mathematic\",\n  \n  \"Applied AI\",\n  \"Environmental Biology\",\n  \"Cellor Biology\",\n  \n  \"AI & Public Wellfare\",\n  \"AI & Public Wellfare\",\n  \"Renewable Energy\",\n  \"Material Science\"\n)\n```\n:::\n\n\nInterestingly, climate change is on longer on this. \n\nFor analysis purposes, we put number 1,7,8 all under one umberalla \"AI & Public Well-fare'.\n\n### Trending Research\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntopic_by_year = res_lda |> \n  tidy(\"gamma\") |> \n  left_join(gtr_meta,by=c(\"document\"=\"id\")) |> \n  mutate(year = year(StartDate)) |> \n  mutate(topic_chr = topic_guess[topic]) |> \n  group_by(topic_chr,year) |>\n  summarise(topic_value = sum(gamma * AwardPounds))\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`summarise()` has grouped output by 'topic_chr'. You can override using the\n`.groups` argument.\n```\n\n\n:::\n\n```{.r .cell-code}\nCutoff_Year=2010\n\nfast_growing = topic_by_year |> \n  filter(year >= Cutoff_Year) |> \n  group_by(topic_chr) |> \n  arrange(topic_chr,year) |> \n  mutate(growth = (topic_value - lag(topic_value))/lag(topic_value) ) |> \n  summarise(avg_growth = mean(growth,na.rm=T)) |> \n  slice_max(avg_growth, n=2)\n\nlatest_top = topic_by_year |> \n  slice_max(year,n=1) |> \n  ungroup() |> \n  slice_max(topic_value,n=1)\n  \ntopic_by_year |>\n  ggplot(aes(x=year,y=topic_value)) +\n  geom_line(aes(color=topic_chr,fill=topic_chr)) + \n  theme_minimal() +\n  ylab(\"topic multiply award\") +\n  gghighlight::gghighlight(\n      (  topic_chr %in% fast_growing$topic_chr \n       | topic_chr %in% latest_top$topic_chr )\n    & year >= Cutoff_Year,\n    line_label_type=\"sec_axis\"\n  ) +\n  scale_color_brewer(palette=\"Set2\") +\n  geom_vline(aes(xintercept=Cutoff_Year),linetype=\"dashed\") + \n  ggtitle(sprintf(\"Growing Topics Since %s\", Cutoff_Year))\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in geom_line(aes(color = topic_chr, fill = topic_chr)): Ignoring\nunknown aesthetics: fill\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Tried to calculate with group_by(), but the calculation failed.\nFalling back to ungrouped filter operation...\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nlabel_key: topic_chr\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](05_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n:::\n\n\n## Appendix\n\n### Developing a Visualization for Topic Modeling\\*\\*\n\nI found bi-gram graph compensate traditional beta count graph. Instead of \"reading tea leafs\", you can try read along the edge.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-summary=\"draft script\"}\nbi_gram = topic_binded |> \n  select(id,abstractText,topic) |> \n  unnest_tokens(pharse,abstractText,'ngrams',n=2) |> \n  separate(pharse, into=c(\"word1\",\"word2\"),sep=\" \") |> \n  anti_join(stop_words, c(\"word1\"=\"word\")) |> \n  anti_join(stop_words, c(\"word2\"=\"word\")) |> \n  count(topic,word1,word2,sort=T)\n\ntypical_graph = bi_gram |> \n  filter(!is.na(word1) & !is.na(word2)) |>\n  group_by(topic) |>\n  slice_max(n,n=20) |> \n  relocate(word1,word2) |> \n  as_tbl_graph()\n\nG = list()\nfor (i in c(2,10,8,9)) {\n  g = typical_graph |> \n    activate(edges) |>\n    filter(topic == i) |> \n    activate(nodes) |> \n    filter(!node_is_isolated())\n  if(length(g)==0) next()\n  plot_g = g |> \n    ggraph('kk') +\n    geom_edge_link(aes(width=n, alpha=n),trans=\"log\",color=\"royalblue\") +\n    geom_node_text(aes(label=name),repel = T) +\n    geom_node_point(size=5) +\n    theme_void() +\n    ggtitle(paste(\"topic\",i))\n  G = append(G, list(plot_g))\n}\nggpubr::ggarrange(plotlist=G,ncol=2, nrow=2)\n```\n:::\n\n\n### List of all Topics From the Frist Extraction\n\n\n::: {.cell}\n\n```{.r .cell-code  code-summary=\"plot all topics trained so far\"}\nG=map(1:10,~plot_topics(model=topics,\n                        reps_tk=bi_gram_tok, \n                        reps_docs=typical_docs,\n                        topic_ki=.x))\nggpubr::ggarrange(plotlist=G,nrow=10)\n```\n\n::: {.cell-output-display}\n![](05_files/figure-html/unnamed-chunk-22-1.png){width=1440}\n:::\n:::\n\n\n### List of All Topic Extraction for Research Grant Only\n\nThe topic read\n\n\n::: {.cell}\n\n```{.r .cell-code  code-summary=\"plot all topics trained so far\"}\nG=map(1:10,~plot_topics(model=res_lda,\n                        reps_tk=res_bi_gram, \n                        reps_docs=res_reps_top,\n                        topic_ki=.x,\n                        color= \"coral2\"\n                        ))\nggpubr::ggarrange(plotlist=G,nrow=10)\n```\n\n::: {.cell-output-display}\n![](05_files/figure-html/unnamed-chunk-23-1.png){width=1440}\n:::\n:::\n",
    "supporting": [
      "05_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}