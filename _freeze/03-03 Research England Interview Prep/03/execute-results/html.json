{
  "hash": "49cd2983b26d820409ccb6a4c6822333",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Basic Text Ananlysis - Word Occurance\"\n---\n\n\n## Overview\n\n::: {.cell}\n\n```{.r .cell-code  code-summary=\"set up and load data\"}\nrequire(tidyverse)\nrequire(readr)\nrequire(tidyr)\nrequire(arrow)\nrequire(tidytext)\nrequire(ggplot2)\nrequire(ggrepel)\nrequire(gghighlight)\n\ngtr_desc = read_parquet(\"data/gtr.parquet\")\ngtr_meta = read_csv(\"data/projectsearch-1709481069771.csv\") |> \n  mutate(across(ends_with(\"Date\"), ~as.Date(.x,\"%d/%m/%Y\")))\n```\n:::\n\n\n## Cleaning\n\n**overview**\n\n- Majority of data and link can join\n- Description and Title contains duplication:\n  - This is due to **project migration** when person of interests changes occupation;\n  - When this happens the `ProjectReference` will ends with a `slash`.\n\n### How well does the two data set join\n\n\n::: {.cell}\n\n```{.r .cell-code  code-summary=\"validation\"}\nJOIN_META_KEY = c(\"id\"=\"ProjectId\")\n\ndesc_key = gtr_desc[[names(JOIN_META_KEY)]]\nmeta_key = gtr_meta[[JOIN_META_KEY[[1]]]]\n\nstopifnot(\n  !any(duplicated(desc_key)),\n  !any(duplicated(meta_key))\n)\ncan_join = intersect(desc_key, meta_key)\ndesc_cant_join = setdiff(desc_key, meta_key)\nmeta_cant_join= setdiff(meta_key, desc_key)\n\npcg = round(length(can_join) / nrow(gtr_desc) * 100)\n\nmessage(glue::glue(\n  \"{ pcg } % of description can find matching porject id in the csv export;\\n\",\n  \"\\nNumbers breakdown:\\n\",\n  \"\\t - {length(can_join)} can join;\\n\",\n  \"\\t - {length(desc_cant_join)} description will be taken out;\\n\",\n  \"\\t - {length(meta_cant_join)} from csv file will be taken out;\\n\"\n))\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n86 % of description can find matching porject id in the csv export;\n\nNumbers breakdown:\n\t - 4453 can join;\n\t - 722 description will be taken out;\n\t - 722 from csv file will be taken out;\n```\n\n\n:::\n:::\n\n\n\n### Linked/Duplicated project\n\n\n::: {.cell}\n\n```{.r .cell-code  code-summary=\"partial project or migrated project\"}\n## migrated project consist of this pattern\nPARTIAL_PTTN='(/[1-9])$'\n\n## waggle some columns for analytics\ngtr_pj = gtr_meta |>\n  mutate(\n    is_partial = str_detect(ProjectReference, PARTIAL_PTTN),\n    project_ref = str_replace(ProjectReference,PARTIAL_PTTN,\"\"),\n    part = str_extract(ProjectReference, PARTIAL_PTTN) |> \n      str_extract(\"\\\\d+\") |> \n      as.numeric() |> \n      coalesce(0)\n  ) |> \n  # filter(is_partial) |> \n  group_by(project_ref) |>\n  mutate(occurance = n()) |> \n  ungroup() |> \n  relocate(ProjectReference, FundingOrgName, LeadROName, ProjectId, \n           is_partial,project_ref,part,occurance\n           )\n\n## early stop if this is no longer true\nstopifnot(\n  \"Project Reference is Unique!\"=length(unique(gtr_pj$ProjectReference)) == nrow(gtr_pj),\n  \"Project Refrence contain null!\"=!any(is.na(gtr_pj$ProjectReference))\n)\n\n## a lot of these are false duplicate? or have they simply not been included in \n## the project? \ngtr_pj |>\n  group_by(occurance) |> \n  summarise(n_projects=n())\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 2\n  occurance n_projects\n      <int>      <int>\n1         1       4984\n2         2        182\n3         3          9\n```\n\n\n:::\n\n```{.r .cell-code  code-summary=\"partial project or migrated project\"}\n## actually majority of these project will false alert\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code  code-summary=\"examples of inheritance projects\"}\nsmp=sample(1:94,1)# 9/3 + 183/2 \ngtr_pj |> \n  filter(occurance !=1) |> \n  group_by(project_ref) |>\n  filter(cur_group_id() == smp) |> \n  left_join(select(gtr_desc, id,abstractText,title), by = c(\"ProjectId\"=\"id\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 31\n# Groups:   project_ref [1]\n  ProjectReference FundingOrgName LeadROName    ProjectId is_partial project_ref\n  <chr>            <chr>          <chr>         <chr>     <lgl>      <chr>      \n1 EP/V008242/2     EPSRC          University o… 510EB79C… TRUE       EP/V008242 \n2 EP/V008242/1     EPSRC          University o… 2A690B5E… TRUE       EP/V008242 \n# ℹ 25 more variables: part <dbl>, occurance <int>, Department <chr>,\n#   ProjectCategory <chr>, PISurname <chr>, PIFirstName <chr>,\n#   PIOtherNames <lgl>, `PI ORCID iD` <chr>, StudentSurname <chr>,\n#   StudentFirstName <chr>, StudentOtherNames <lgl>, `Student ORCID iD` <chr>,\n#   Title <chr>, StartDate <date>, EndDate <date>, AwardPounds <dbl>,\n#   ExpenditurePounds <dbl>, Region <chr>, Status <chr>, GTRProjectUrl <chr>,\n#   FundingOrgId <chr>, LeadROId <chr>, PIId <chr>, abstractText <chr>, …\n```\n\n\n:::\n:::\n\nAlthough the project will have different `id`. The content is actually the same.\nSo it is important these are taken out before input for analysis.\n\nFor the analysis, we only need to take the first project which end with /1\n\nWe will need to know which rows to keep which rows to delete\n\n\n::: {.cell}\n\n```{.r .cell-code  code-summary=\"keep only the first project\"}\nunique_prj = gtr_pj |>\n  relocate(ProjectReference, project_ref, ProjectId) |> \n  group_by(project_ref) |> \n  mutate(rn=row_number()) |> \n  filter(rn==1) |> \n  select(-rn) |> \n  inner_join(select(gtr_desc, id,abstractText,title), by = c(\"ProjectId\"=\"id\")) |> \n  ungroup()\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code  code-summary=\"check further duplication\"}\nrepeated_text = unique_prj |> \n  group_by(abstractText) |> \n  mutate(n=n()) |> \n  filter(n!=1) |>\n  arrange(abstractText)\n\nrepeated_text |> \n  select(ProjectReference,title,abstractText, ProjectId)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 316 × 4\n# Groups:   abstractText [110]\n   ProjectReference title                                 abstractText ProjectId\n   <chr>            <chr>                                 <chr>        <chr>    \n 1 27744            Enhancing Type 2 Diabetes treatment … \"**NEED:** … 6A378D2F…\n 2 10025411         Research and Development support for… \"**NEED:** … B9B20477…\n 3 ST/G003467/1     High speed imaging with diamond dyno… \"1. The pur… 382C54EA…\n 4 ST/G003475/1     High speed imaging with diamond dyno… \"1. The pur… BBD58755…\n 5 NE/V012908/1     Dry deposition processes of volatile… \"A large ra… BD2B6410…\n 6 NE/V01272X/1     Dry deposition processes of volatile… \"A large ra… B7C88680…\n 7 EP/F047770/1     Carbon Dioxide and Alkanes as Electr… \"A major so… 041635B4…\n 8 EP/F047789/1     Carbon Dioxide and Alkanes as Electr… \"A major so… 7FF78CAF…\n 9 EP/F047878/1     Carbon Dioxide and Alkanes as Electr… \"A major so… C595D2BE…\n10 EP/F04772X/1     Carbon Dioxide and Alkanes as Electr… \"A major so… 60F0EBC9…\n# ℹ 306 more rows\n```\n\n\n:::\n:::\n\nEven with project dropped, most of these still have little descriptions\n\n\n## Word Count and Keyword Summary\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Take the repeated test one out for now.\nanalysis_prj = unique_prj |> \n  anti_join(repeated_text, by=\"ProjectId\") |> \n  mutate(year = lubridate::year(StartDate))\n\n\n## function for tokenise target fiel\ntokenize_words_group = function(df, col, group_col) {\n  df |>\n    # preserve chained keywords\n    mutate(text_field = str_replace({{col}}, \n                                    '(A|a)rtificial (I|i)ntelligence', \n                                    'artificialintelligence') |> \n             str_replace(\"machine learning\",\n                         'machinelearning')\n           ) |> \n    unnest_tokens(word,text_field, token=\"words\") |> \n    anti_join(stop_words,\"word\") |> \n    mutate(word=str_replace(word,'artificialintelligence','artificial-intelligence') |> \n             str_replace('machinelearning','machin-learning')\n           ) |> \n    group_by(word, {{group_col}}) |> \n    summarise(n_prj = length(unique(ProjectId)), .groups=\"drop\" ) |> \n    arrange(desc({{group_col}}),desc(n_prj)) |> \n    ungroup()\n}\n\nrank_words = function(word_token, group_col) {\n  word_token |>\n    group_by({{group_col}}) |> \n    dplyr::arrange(desc({{group_col}}),desc(n_prj)) |>\n    dplyr::mutate(rank = row_number()) |>\n    ungroup()\n}\n\nplot_top_n = function(word_token, n, group_col) {\n  top_n = rank_words(word_token, {{group_col}}) |> \n    filter(rank <= n)\n  top_n |> \n    arrange({{group_col}},rank) |>\n    ggplot(aes(x=n_prj, y = reorder_within(word, n_prj, {{group_col}} ))) +\n    geom_col(fill=\"midnightblue\") + \n    scale_y_reordered() +\n    facet_wrap(~ eval(enquo(group_col)), scales=\"free_y\") +\n    xlab(\"number of porject\") + ylab(\"word\")\n}\n\ntitle_word_by_year = analysis_prj |> \n  tokenize_words_group(title, year)\n\nabstrc_word_by_year = analysis_prj |> \n  tokenize_words_group(abstractText, year)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntitle_word_by_year |>\n  filter(year >= 2016) |>\n  mutate(year = as.character(year)) |>\n  plot_top_n(15, year) +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](03_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nabstrc_word_by_year |>\n  filter(year >= 2016) |>\n  mutate(year = as.character(year)) |>\n  plot_top_n(15, year) +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](03_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n## track progression of top n over years\nplt_style_change = function(text_by_year, \n                            fav_words=c(\"artificial-intelligence\",\"ai\",\"health\", \"machine-learning\",\"learning\"),\n                            limit_rank = 10,\n                            weight = c(\"pcg\", \"absolute\")\n                            ) {\n  \n  if(weight[1] == \"absolute\") {\n    weightQ = quo(n_prj)\n  } else if (weight[1] == \"pcg\") {\n    weightQ = quo(pcg_prj)\n  } else {\n    stop()\n  }\n  \n  word_ranked = text_by_year |> \n    # filter(year > 2010) |> \n    rank_words(year) |> \n    group_by(year) |> \n    mutate(pcg_prj = n_prj/sum(n_prj)) |> \n    ungroup()\n  \n  top_n = word_ranked |>\n    filter(rank <= limit_rank) |> \n    ## join back words that were crop out in top n ranking\n    select(-n_prj, -rank,-pcg_prj)\n  \n  top_n_complete =\n    tidyr::expand(top_n, year, word) |> \n    left_join(word_ranked, c(\"year\",\"word\")) |> \n    mutate(across(c(n_prj, pcg_prj), ~coalesce(.x,0))) |> \n    mutate(rank = coalesce(rank, max(word_ranked$rank + 1)))\n    \n  top_n_complete |> \n    filter(year >= 2010 & year <= 2023) |> \n    ggplot(aes(x=year,y= !! weightQ, color=word)) + \n    geom_line() +\n    geom_point() +\n    theme(legend.position = \"none\", axis.text.y.right = element_text(size = 20)) + \n    # scale_y_reverse() +\n    gghighlight(word %in% fav_words,\n                unhighlighted_params=list(alpha=0.2),\n                line_label_type = \"text_path\"#\"sec_axis\"\n                ) +\n    scale_color_brewer(palette=\"Set2\") +\n    theme_minimal()\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nINTERESTING_WORDS = c(\"artificial-intelligence\",\"ai\",\"health\")\ntitle_word_by_year |> \n  plt_style_change(\n    INTERESTING_WORDS,\n    weight = \"pcg\"\n  ) +\n  ylab(\"propotion of project\") +\n  ggtitle(\"Keywords mention in project title\",\n          stringr::str_wrap(glue::glue(\"The mention of 'health' seen a sharp raise in 2020. \",\n          \"Researchers are more comformatble using term 'ai' rather than 'aritificial-intelligence'\"),80)\n          )\n```\n\n::: {.cell-output-display}\n![](03_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nINTERESTING_WORDS = c(\"artificial-intelligence\",\"ai\",\"health\")\ntitle_word_by_year |> \n  plt_style_change(\n    INTERESTING_WORDS,\n    weight=\"absolute\"\n  ) +\n  ylab(\"absolute number of project\")\n```\n\n::: {.cell-output-display}\n![](03_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nINTERESTING_WORDS=c(\"ai\",\"artificial-intelligence\",\"covid\",\"health\",\"artificial\")\nabstrc_word_by_year |> \n  plt_style_change(\n    fav_words=INTERESTING_WORDS,\n    limit_rank = 30,\n    weight = \"pcg\"\n  )\n```\n\n::: {.cell-output-display}\n![](03_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nINTERESTING_WORDS=c(\"ai\",\"artificial-intelligence\",\"covid\",\"health\",\"artificial\")\nabstrc_word_by_year |> \n  plt_style_change(\n    fav_words=INTERESTING_WORDS,\n    limit_rank = 30,\n    weight=\"absolute\"\n  )\n```\n\n::: {.cell-output-display}\n![](03_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n",
    "supporting": [
      "03_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}